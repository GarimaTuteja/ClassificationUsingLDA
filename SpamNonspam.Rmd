```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loadpackages, warning=FALSE, message=FALSE}
pacman::p_load(caret, data.table, MASS, ggplot2,dplyr,gains)
options(digits = 3)
knitr::opts_chunk$set(echo = TRUE, fig.width=12, fig.height=6, fig.path = 'Figs/')
theme_set(theme_classic())
```

```{r Read the Data }
# Read the spambase data and add column names to the data provided 
spamnonspam <-read.csv("spambase.data", header=FALSE)
names(spamnonspam) <- c("word_freq_make", "word_freq_address", "word_freq_all", 
                        "word_freq_3d", "word_freq_our", "word_freq_over", 
                        "word_freq_remove", "word_freq_internet", 
  "word_freq_order", "word_freq_mail", "word_freq_receive", "word_freq_will", 
    "word_freq_people", "word_freq_report", "word_freq_addresses", "word_freq_free", 
    "word_freq_business", "word_freq_email", "word_freq_you", "word_freq_credit", 
    "word_freq_your", "word_freq_font", "word_freq_000", "word_freq_money", 
    "word_freq_hp", "word_freq_hpl", "word_freq_george", "word_freq_650", 
  "word_freq_lab", 
    "word_freq_labs", "word_freq_telnet", "word_freq_857", "word_freq_data", 
    "word_freq_415", "word_freq_85", "word_freq_technology", "word_freq_1999", 
    "word_freq_parts", "word_freq_pm", "word_freq_direct", "word_freq_cs", 
  "word_freq_meeting", 
    "word_freq_original", "word_freq_project", "word_freq_re", "word_freq_edu", 
    "word_freq_table", "word_freq_conference", "char_freq_ch;", "char_freq_ch(", 
    "char_freq_ch[", "char_freq_ch!", "char_freq_ch$", "char_freq_ch#", 
  "capital_run_length_average", 
    "capital_run_length_longest", "capital_run_length_total", "class")


```


```{r Normalizing & Spiltting data into Training and Validation}
norm.values <- preProcess(spamnonspam[ ,-58], method = c("center", "scale"))
spamnonspam.norm<-predict(norm.values,spamnonspam)
set.seed(42)
training.index <- createDataPartition(spamnonspam.norm$class, p = 0.8, list = FALSE)
spamnonspam.train <- spamnonspam[training.index, ]
spamnonspam.valid <- spamnonspam[-training.index, ]
```

To examine 10 predictors for which the difference between the spam-class average and NON-SPAM class average is highest we first have to filter the data into SPAM and NONSPAM based on the data which is provided then take the average values for each of the predictors in both the filtered datasets i.e for SPAM and NON-SPAM, and then we have to find the absolute difference between the averages as can be seen in the following code and then we can sort the difference and get the top 10 predictors which are required.
The top 10 predictors are 
```{r Finding the top 10 variables}
nonspam <- filter(spamnonspam.norm,class==0)
spam <- filter(spamnonspam.norm,class==1)
nonspamaverage <- colMeans(nonspam[,-58])
spamaverage <-colMeans(spam[,-58])
averagedifference<-abs(nonspamaverage-spamaverage)
averagedifference.vec <-as.vector(averagedifference)
names(averagedifference.vec) <- names(averagedifference)
top10predictors <-head(sort(averagedifference,decreasing=TRUE),10)
top10predictorsname <-as.data.frame(names(top10predictors))
colnames(top10predictorsname) <-c("Top 10 predictors")
top10predictorsname
```

The following is LDA performed using the training dataset with the top 10 identified predictors identified above. We included only the identified predictors in the test and training dataset in the following code and trained the model using the training dataset.

```{r Run LDA Using top10 predictors}
toppredictors <- names(top10predictors)
ldapredcitors <- c(toppredictors,'class')
pred.data.train <- spamnonspam.train[,ldapredcitors]
pred.data.valid <- spamnonspam.valid[,ldapredcitors]
ldamodel <-lda(class~., data = pred.data.train)
ldamodel
```

Prior probability is the probability which is calculated from the frequency distribution of various classes present in the dataset. 

```{r Prior Probabiltiy}
ldamodel$prior
```
From above we can see prior probability of the email being Non Spam is 0.604 and Prior probability of the email being SPAM is 0.396,which we can see from the data that records which are classified as SPAM are 1813 out 4601, which has a relative frequency of 0.39 same goes for the Non SPAM records.

Following is the linear discriminant
```{r Coefficient of linear discriminant}
ldamodel$scaling

```

Coefficient of linear discriminant basically tells us what are the weighted average of each predcitors and by means of this we can find the LD Scores 
For eg If we multiply each value of LDA1 (the first linear discriminant)
by the corresponding elements of the predictor variables and sum them (0.334727×word_freq_your+1.013978×word_freq_000  +..) 
we get a LD score for each observation. 


Generate linear discriminants using your analysis. How are they used in classifying spams and non-spams?

```{r Predcition }
# Predcitions using validation dataset
spamnonspam.valid.pred  <- predict(ldamodel,pred.data.valid)
head(spamnonspam.valid.pred$x,10)
head(spamnonspam.valid.pred$posterior,10)
```

We can classify spams and nonspams on the basis posterior probability as it tells the the probability of an observation belonging to a class. For eg the first record in output has the probability of belonging to NONSPAM class is 0.632 and the probability of belonging to SPAM is 0.3677. So if we use the default 0.5 cut off then we can identify this email as NONSPAM.Same goes for the other observations

There is only 1 LD in the model as the number of classes are 2, from the rule of thumb we can say that LD is number of classes -1. 


Generate LDA plot using the training and validation data. What information is presented in these plots? How are they different?


From the plots below, we can see that the LDA plots for training and validation datasets were similar. The observations in the plots show distribution spam and non-spam class in the training and validation dataset. 
```{r }
 lda.model.train.plot <- data.frame(pred.data.train, predict(ldamodel)$x)
ggplot(lda.model.train.plot, aes(LD1,fill=class)) +
  geom_histogram(color = "coral1", alpha=0.6) + 
  ggtitle("LDA plot for the training data set")

 lda.model.valid.plot <- data.frame(pred.data.valid, spamnonspam.valid.pred$x)
ggplot(lda.model.valid.plot, aes(LD1,fill=class)) +
  geom_histogram(color = "coral1", alpha=0.6) +
  ggtitle("LDA plot for the validation data set")

plot(ldamodel)
ldamodel2 <-lda(class~., data = pred.data.valid)
plot(ldamodel2)

```




Generate the relevant confusion matrix. What are the sensitivity and specificity?

```{r Confusion Matrix}
predvsactual <- table(spamnonspam.valid.pred$class,spamnonspam.valid$class)  
confusionMatrix(predvsactual)

```
Sensitivity is 0.949 & Specificity is 0.686 


Generate lift and decile charts for the validation dataset and evaluate the effectiveness of the model in identifying spams.
```{r Lift Chart}
gain <- gains(pred.data.valid$class,spamnonspam.valid.pred$x)
plot(c(0,gain$cume.pct.of.total*sum(as.numeric(pred.data.valid$class)))
     ~c(0,gain$cume.obs),
     xlab = 'No.Of.Cases', ylab = 'Cumulative',
     main = "Lift Chart for Predictions",
     col = "seagreen",
     type = "l")
lines(c(0,sum(pred.data.valid$class))~c(0,dim(pred.data.valid)[1]), lty = 5)
```
As we can see from the Lift Chart,our model have a higher lift than NIR, which can be also seen in the confusion matrix we generated that the NIR is 61% and accuracy of our model is 84%.

```{r Decile Chart}
barplot(gain$mean.resp/mean(pred.data.valid$class), names.arg = gain$depth, space = 1.3,
        xlab = "Percentile", ylab = "Mean Response", main = "Decile-wise lift chart",
        col = "coral1", border = NA)


```



For this part we have to change the cut off to 0.2 to see what impact does it have on the accuracy of our model.
On decreasing the probability threshold from 0.5 to 0.2 which means the probability of classifying the emails as spam will increase. Hence, the emails which were previously nonspam will now be classified as spam which means the false positive values will increase.
```{r}

confusionMatrix(table(as.numeric(spamnonspam.valid.pred$posterior[,2] > 0.2),
pred.data.valid$class), positive = "1")

```

